{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bandits import Bandit\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# Include your imports here, if any are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of ten bandit objects initialized in the list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandits = [Bandit(random.random()*4-2) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04364432528747145"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits[0].pullLever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.zeros((10))\n",
    "n = np.zeros((10))\n",
    "\n",
    "rewards = []\n",
    "\n",
    "def run_greedy():\n",
    "    # TODO: Implement the greedy algorithm here\n",
    "    # Return the reward from the bandits in a list\n",
    "    \n",
    "    \n",
    "    max_index = np.argmax(q)\n",
    "    rwd = bandits[max_index].pullLever()\n",
    "    q[max_index] = (q[max_index]*n[max_index]+rwd)/(n[max_index]+1)\n",
    "    n[max_index] = n[max_index]+1\n",
    "    rewards.append(rwd)\n",
    "    \n",
    "    return rewards\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative average of rewards as the number of iterations increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_points = []\n",
    "x_points = []\n",
    "\n",
    "for i in range(1,2001):\n",
    "    rwds = run_greedy()\n",
    "    avg = sum(rwds)/i\n",
    "    y_points.append(avg)\n",
    "    x_points.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_points,y_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\epsilon$-greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epsilon_greedy(epsilon):\n",
    "    # TODO: Implement the epsilon greedy algorithm here\n",
    "    # Return the reward from the bandits in a list\n",
    "    if random.random() < epsilon:\n",
    "        r = random.randint(0,9)\n",
    "\n",
    "        rwd = bandits[r].pullLever()\n",
    "        q[r] = (q[r]*n[r]+rwd)/(n[r]+1)\n",
    "        n[r] = n[r]+1\n",
    "        rewards.append(rwd)\n",
    "\n",
    "    else:\n",
    "        run_greedy()\n",
    "\n",
    "    return rewards\n",
    "        \n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative average of rewards as the number of iterations increases but for various values of $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    q = np.zeros((10))\n",
    "    n = np.zeros((10))\n",
    "    \n",
    "    rewards = []\n",
    "    x_points.clear()\n",
    "    y_points.clear()\n",
    "\n",
    "    for i in range(1,2001):\n",
    "        rwds = run_epsilon_greedy(0.2*j)\n",
    "        avg = sum(rwds)/i\n",
    "        y_points.append(avg)\n",
    "        x_points.append(i)\n",
    "\n",
    "    plt.plot(x_points,y_points,label = 'epsilon = {k}'.format(k=0.2*j))\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the $\\epsilon$-greedy algorithm for 1000 iterations and find the optimal $\\epsilon$ value by plotting the cumulative average of rewards for various values of $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,num=100,endpoint=True, retstep=False, dtype=None, axis=0)\n",
    "y = []\n",
    "\n",
    "for i in range(100):\n",
    "    q = np.zeros((10))\n",
    "    n = np.zeros((10))\n",
    "    \n",
    "    rewards = []\n",
    "\n",
    "    for j in range(1,1001):\n",
    "        rwds = run_epsilon_greedy(x[i])\n",
    "        avg = sum(rwds)/j\n",
    "\n",
    "    y.append(avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "max_index = y.index(max(y))\n",
    "print(\"Optimal epsilon = \",x[max_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimistic Initial Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimistic_greedy(epsilon):\n",
    "    # TODO: Implement the optimistic greedy algorithm here\n",
    "\n",
    "    # Return the reward from the bandits in a list\n",
    "\n",
    "    return run_epsilon_greedy(epsilon)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative average of rewards as the number of iterations increases for an optimistic greedy of $Q_1 = 10$ and a non-optimistic $\\epsilon = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.zeros((10))\n",
    "n = np.zeros((10))\n",
    "for i in range(10):\n",
    "    q[i] = 10\n",
    "\n",
    "x_points.clear()\n",
    "y_points.clear()\n",
    "rewards = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    rwds = run_optimistic_greedy(0)\n",
    "    avg = sum(rwds)/i\n",
    "    y_points.append(avg)\n",
    "    x_points.append(i)\n",
    "\n",
    "plt.plot(x_points,y_points,label = 'Optimistic Greedy')\n",
    "\n",
    "x_pointsE = []\n",
    "y_pointsE = []\n",
    "\n",
    "q = np.zeros((10))\n",
    "n = np.zeros((10))\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    rwds = run_optimistic_greedy(0.1)\n",
    "    avg = sum(rwds)/i\n",
    "    y_pointsE.append(avg)\n",
    "    x_pointsE.append(i)\n",
    "\n",
    "plt.plot(x_pointsE,y_pointsE,label = 'Non-Optimistic Epsilon = 0.1')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional - Upper Confidence Bound (UCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ucb(c):\n",
    "    # TODO: Implement the UCB algorithm here\n",
    "    # Return the reward from the bandits in a list\n",
    "\n",
    "    for i in range(10):\n",
    "        if n[i] == 0:\n",
    "            rwd = bandits[i].pullLever()\n",
    "            q[i] = rwd\n",
    "            rewards.append(rwd)\n",
    "            return rewards\n",
    "\n",
    "    fac = np.array((10))\n",
    "    t = sum(n)\n",
    "    for i in range(10):\n",
    "        fac[i] = q[i]+c*math.sqrt(math.log(t)/n[i])\n",
    "\n",
    "    max_index = np.argmax(fac)\n",
    "    rwd = bandits[max_index].pullLever()\n",
    "    q[max_index] = (q[max_index]*n[max_index]+rwd)/(++n[i])\n",
    "\n",
    "    return rewards\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.zeros((10))\n",
    "n = np.zeros((10))\n",
    "\n",
    "rewards.clear()\n",
    "y_points.clear()\n",
    "x_points.clear()\n",
    "\n",
    "for i in range(1,1001):\n",
    "    rwds = run_ucb(2)\n",
    "    avg = sum(rwds)/i\n",
    "    y_points.append(avg)\n",
    "    x_points.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_points,y_points)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
